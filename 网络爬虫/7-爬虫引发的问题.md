# 爬虫引发的问题

标签： requests

---

## 常用网络爬虫
- 规模小，数据小，爬取速度不敏感，可以用Requests库 90%
- 爬取网站或者系列网站，中规模，数据规模较大，爬取速度敏感，Scrapy爬取携程内容等
- 全网爬取，大规模搜索爬取速度关键，定制开发

## 网络爬虫骚扰
高访问服务器很难提供那么高的性能，受限于编写者的水平和目的，网络爬虫会对Web资源造成巨大的资源开销

## 法律风险

- 数据的产权归属
- 爬虫获取数据后牟利的法律风险
- 隐私泄露，爬虫具备突破简单的访问控制，获得被保护数据从而泄露个人隐私


----------

## 网络爬虫的限制

- 来源审查

判断User-Agent进行限制：检查来访HTTP协议头的Usr-Agent域，只响应浏览器或友好爬虫的访问。

- 发布公告：Robots协议

告知所有爬虫网站的爬取策略，要求遵守。



